{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1626208201948,"user":{"displayName":"Varun Seshu","photoUrl":"","userId":"06913757520347033988"},"user_tz":-330},"id":"5aTY3d37NzMS","outputId":"37633b2a-545d-41bd-815d-497d55f547b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"TxErM6njO3pt"},"source":["## 1. Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10789,"status":"ok","timestamp":1626208213341,"user":{"displayName":"Varun Seshu","photoUrl":"","userId":"06913757520347033988"},"user_tz":-330},"id":"gls61g27O8c1","outputId":"1b9d0614-8a71-4cc3-81bb-228af2cf38ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.1.5)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eta) (2018.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eta) (2.8.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003eta) (1.15.0)\n"]}],"source":["import os\n","import datetime\n","\n","!pip3 install ta\n","import ta\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","np.random.seed(98)\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","\n","from sklearn import metrics\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"hFE9VNU7O9ZX"},"source":["## 2. Configuration"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1626208213343,"user":{"displayName":"Varun Seshu","photoUrl":"","userId":"06913757520347033988"},"user_tz":-330},"id":"yJqujgtIPCDz"},"outputs":[],"source":["prediction_periods = [2, 3, 5, 7, 10]\n","train_test_split_factors = [0.8, 0.75, 0.8, 0.75, 0.8]\n","activation = 'relu'\n","optimizer = 'adam'\n","loss = 'mse'\n","epochs = [10, 25, 20, 25, 20]\n","hidden_layer_configs = [(8, 32, 8), (100, 200, 100), (12, 32, 32, 12), (25, 75, 100, 75, 25), (100, 64, 64)]"]},{"cell_type":"markdown","metadata":{"id":"OGt9aCwtPDV5"},"source":["## 3. Automated model generation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"usqY39PaPGE2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","797/797 [==============================] - 50s 36ms/step - loss: 1.0032\n","\n","Epoch 00001: loss improved from inf to 1.00112, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ASIANPAINT/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","797/797 [==============================] - 29s 36ms/step - loss: 1.3126\n","\n","Epoch 00002: loss did not improve from 1.00112\n","Epoch 3/10\n","797/797 [==============================] - 28s 36ms/step - loss: 0.9462\n","\n","Epoch 00003: loss did not improve from 1.00112\n","Epoch 4/10\n","797/797 [==============================] - 28s 35ms/step - loss: 0.9441\n","\n","Epoch 00004: loss improved from 1.00112 to 0.99800, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ASIANPAINT/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","797/797 [==============================] - 28s 35ms/step - loss: 45.7938\n","\n","Epoch 00005: loss did not improve from 0.99800\n","Epoch 6/10\n","797/797 [==============================] - 27s 34ms/step - loss: 0.8700\n","\n","Epoch 00006: loss did not improve from 0.99800\n","Epoch 7/10\n","797/797 [==============================] - 27s 34ms/step - loss: 0.8556\n","\n","Epoch 00007: loss did not improve from 0.99800\n","Epoch 8/10\n","797/797 [==============================] - 28s 35ms/step - loss: 0.8965\n","\n","Epoch 00008: loss did not improve from 0.99800\n","Epoch 9/10\n","797/797 [==============================] - 27s 33ms/step - loss: 0.9510\n","\n","Epoch 00009: loss improved from 0.99800 to 0.99663, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ASIANPAINT/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","797/797 [==============================] - 27s 34ms/step - loss: 64079023718112.7031\n","\n","Epoch 00010: loss did not improve from 0.99663\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.8405243214708247\n","Mean Squared Error: 1.71004043516821\n","Root Mean Squared Error: 1.3076851437437873\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 1.6594826067881039\n","Mean Squared Error: 6.6657836537413795\n","Root Mean Squared Error: 2.5818178970913848\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","770/770 [==============================] - 31s 35ms/step - loss: 0.9618\n","\n","Epoch 00001: loss improved from inf to 1.00252, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","770/770 [==============================] - 26s 34ms/step - loss: 1.0206\n","\n","Epoch 00002: loss improved from 1.00252 to 1.00066, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","770/770 [==============================] - 28s 37ms/step - loss: 0.9889\n","\n","Epoch 00003: loss did not improve from 1.00066\n","Epoch 4/10\n","770/770 [==============================] - 28s 37ms/step - loss: 1.0020\n","\n","Epoch 00004: loss did not improve from 1.00066\n","Epoch 5/10\n","770/770 [==============================] - 29s 38ms/step - loss: 1.0291\n","\n","Epoch 00005: loss improved from 1.00066 to 0.99957, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","770/770 [==============================] - 28s 37ms/step - loss: 0.9234\n","\n","Epoch 00006: loss improved from 0.99957 to 0.99947, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","770/770 [==============================] - 30s 38ms/step - loss: 0.9374\n","\n","Epoch 00007: loss improved from 0.99947 to 0.99678, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 8/10\n","770/770 [==============================] - 29s 38ms/step - loss: 1.1298\n","\n","Epoch 00008: loss improved from 0.99678 to 0.99230, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","770/770 [==============================] - 29s 37ms/step - loss: 0.9965\n","\n","Epoch 00009: loss improved from 0.99230 to 0.97395, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","770/770 [==============================] - 29s 38ms/step - loss: 0.9205\n","\n","Epoch 00010: loss improved from 0.97395 to 0.96832, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/ADANIPORTS/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7383918978536191\n","Mean Squared Error: 0.995022787613106\n","Root Mean Squared Error: 0.997508289495935\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.2857339362588798\n","Mean Squared Error: 9.534776857405236\n","Root Mean Squared Error: 3.087843399106444\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","763/763 [==============================] - 33s 38ms/step - loss: 1.1687\n","\n","Epoch 00001: loss improved from inf to 1.01107, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJ-AUTO/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","763/763 [==============================] - 30s 39ms/step - loss: 0.9415\n","\n","Epoch 00002: loss improved from 1.01107 to 1.00041, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJ-AUTO/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","763/763 [==============================] - 29s 38ms/step - loss: 0.9177\n","\n","Epoch 00003: loss did not improve from 1.00041\n","Epoch 4/10\n","763/763 [==============================] - 28s 37ms/step - loss: 0.8713\n","\n","Epoch 00004: loss improved from 1.00041 to 0.99872, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJ-AUTO/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","763/763 [==============================] - 28s 37ms/step - loss: 0.9232\n","\n","Epoch 00005: loss improved from 0.99872 to 0.99863, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJ-AUTO/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","763/763 [==============================] - 27s 35ms/step - loss: 0.8507\n","\n","Epoch 00006: loss improved from 0.99863 to 0.99482, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJ-AUTO/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","763/763 [==============================] - 27s 35ms/step - loss: 55153.3355\n","\n","Epoch 00007: loss did not improve from 0.99482\n","Epoch 8/10\n","763/763 [==============================] - 27s 35ms/step - loss: 1.0361\n","\n","Epoch 00008: loss did not improve from 0.99482\n","Epoch 9/10\n","763/763 [==============================] - 28s 36ms/step - loss: 0.9491\n","\n","Epoch 00009: loss did not improve from 0.99482\n","Epoch 10/10\n","763/763 [==============================] - 27s 35ms/step - loss: 0.8929\n","\n","Epoch 00010: loss did not improve from 0.99482\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7134770569170725\n","Mean Squared Error: 0.9985803976573874\n","Root Mean Squared Error: 0.9992899467408783\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 1.6228919716353258\n","Mean Squared Error: 5.166569024806329\n","Root Mean Squared Error: 2.273008804383813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","781/781 [==============================] - 32s 36ms/step - loss: 0.9321\n","\n","Epoch 00001: loss improved from inf to 1.00175, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/AXISBANK/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","781/781 [==============================] - 28s 36ms/step - loss: 0.9487\n","\n","Epoch 00002: loss improved from 1.00175 to 1.00100, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/AXISBANK/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","781/781 [==============================] - 28s 36ms/step - loss: 0.9112\n","\n","Epoch 00003: loss did not improve from 1.00100\n","Epoch 4/10\n","781/781 [==============================] - 28s 36ms/step - loss: 1.1736\n","\n","Epoch 00004: loss improved from 1.00100 to 1.00073, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/AXISBANK/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","781/781 [==============================] - 29s 37ms/step - loss: 1.1202\n","\n","Epoch 00005: loss improved from 1.00073 to 1.00068, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/AXISBANK/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","781/781 [==============================] - 29s 38ms/step - loss: 0.9130\n","\n","Epoch 00006: loss did not improve from 1.00068\n","Epoch 7/10\n","781/781 [==============================] - 29s 37ms/step - loss: 1.4101\n","\n","Epoch 00007: loss did not improve from 1.00068\n","Epoch 8/10\n","781/781 [==============================] - 29s 37ms/step - loss: 0.9956\n","\n","Epoch 00008: loss did not improve from 1.00068\n","Epoch 9/10\n","781/781 [==============================] - 28s 36ms/step - loss: 1.0179\n","\n","Epoch 00009: loss did not improve from 1.00068\n","Epoch 10/10\n","781/781 [==============================] - 27s 34ms/step - loss: 0.9193\n","\n","Epoch 00010: loss did not improve from 1.00068\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7352435930082677\n","Mean Squared Error: 1.000033980361562\n","Root Mean Squared Error: 1.0000169900364504\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.2026109305513786\n","Mean Squared Error: 8.974863232864662\n","Root Mean Squared Error: 2.9958076094543626\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","793/793 [==============================] - 31s 35ms/step - loss: 0.8580\n","\n","Epoch 00001: loss improved from inf to 1.00229, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","793/793 [==============================] - 27s 34ms/step - loss: 0.9465\n","\n","Epoch 00002: loss did not improve from 1.00229\n","Epoch 3/10\n","793/793 [==============================] - 27s 34ms/step - loss: 0.9251\n","\n","Epoch 00003: loss improved from 1.00229 to 1.00012, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","793/793 [==============================] - 27s 34ms/step - loss: 0.9887\n","\n","Epoch 00004: loss improved from 1.00012 to 0.99920, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","793/793 [==============================] - 27s 34ms/step - loss: 9745118.6928\n","\n","Epoch 00005: loss did not improve from 0.99920\n","Epoch 6/10\n","793/793 [==============================] - 27s 34ms/step - loss: 0.8538\n","\n","Epoch 00006: loss improved from 0.99920 to 0.99054, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","793/793 [==============================] - 28s 36ms/step - loss: 0.9785\n","\n","Epoch 00007: loss improved from 0.99054 to 0.98596, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 8/10\n","793/793 [==============================] - 27s 34ms/step - loss: 0.9298\n","\n","Epoch 00008: loss improved from 0.98596 to 0.97524, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","793/793 [==============================] - 28s 35ms/step - loss: 0.9799\n","\n","Epoch 00009: loss did not improve from 0.97524\n","Epoch 10/10\n","793/793 [==============================] - 27s 34ms/step - loss: 1.0762\n","\n","Epoch 00010: loss improved from 0.97524 to 0.95845, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJFINANCE/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7117162101752099\n","Mean Squared Error: 1.2049287756638998\n","Root Mean Squared Error: 1.0976924777294867\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.598138879705925\n","Mean Squared Error: 16.05729491451199\n","Root Mean Squared Error: 4.007155464230454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","780/780 [==============================] - 30s 33ms/step - loss: 38231038.5563\n","\n","Epoch 00001: loss improved from inf to 44013800.00000, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJFINSV/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","780/780 [==============================] - 28s 36ms/step - loss: 2.6195\n","\n","Epoch 00002: loss improved from 44013800.00000 to 1.72832, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJFINSV/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","780/780 [==============================] - 27s 35ms/step - loss: 379.1756\n","\n","Epoch 00003: loss did not improve from 1.72832\n","Epoch 4/10\n","780/780 [==============================] - 27s 34ms/step - loss: 986.2162\n","\n","Epoch 00004: loss did not improve from 1.72832\n","Epoch 5/10\n","780/780 [==============================] - 27s 34ms/step - loss: 0.8412\n","\n","Epoch 00005: loss improved from 1.72832 to 0.99920, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJFINSV/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","780/780 [==============================] - 27s 34ms/step - loss: 111.5275\n","\n","Epoch 00006: loss did not improve from 0.99920\n","Epoch 7/10\n","780/780 [==============================] - 27s 35ms/step - loss: 0.9399\n","\n","Epoch 00007: loss did not improve from 0.99920\n","Epoch 8/10\n","780/780 [==============================] - 27s 35ms/step - loss: 1.3264\n","\n","Epoch 00008: loss did not improve from 0.99920\n","Epoch 9/10\n","780/780 [==============================] - 27s 35ms/step - loss: 0.9826\n","\n","Epoch 00009: loss improved from 0.99920 to 0.99903, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJFINSV/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","780/780 [==============================] - 26s 34ms/step - loss: 1.0913\n","\n","Epoch 00010: loss improved from 0.99903 to 0.99860, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BAJAJFINSV/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7292500351471302\n","Mean Squared Error: 0.9969326925330768\n","Root Mean Squared Error: 0.9984651684125375\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.13051092529865\n","Mean Squared Error: 8.509037778937195\n","Root Mean Squared Error: 2.917025501934667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","787/787 [==============================] - 30s 34ms/step - loss: 1.0217\n","\n","Epoch 00001: loss improved from inf to 1.00175, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BPCL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","787/787 [==============================] - 27s 34ms/step - loss: 0.9081\n","\n","Epoch 00002: loss improved from 1.00175 to 1.00089, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BPCL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","787/787 [==============================] - 27s 35ms/step - loss: 0.9849\n","\n","Epoch 00003: loss did not improve from 1.00089\n","Epoch 4/10\n","787/787 [==============================] - 27s 34ms/step - loss: 1.1214\n","\n","Epoch 00004: loss did not improve from 1.00089\n","Epoch 5/10\n","787/787 [==============================] - 27s 34ms/step - loss: 0.8855\n","\n","Epoch 00005: loss did not improve from 1.00089\n","Epoch 6/10\n","787/787 [==============================] - 27s 34ms/step - loss: 1.1274\n","\n","Epoch 00006: loss did not improve from 1.00089\n","Epoch 7/10\n","787/787 [==============================] - 27s 34ms/step - loss: 0.9255\n","\n","Epoch 00007: loss did not improve from 1.00089\n","Epoch 8/10\n","787/787 [==============================] - 27s 34ms/step - loss: 1.0109\n","\n","Epoch 00008: loss improved from 1.00089 to 1.00075, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BPCL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","787/787 [==============================] - 26s 33ms/step - loss: 1.0305\n","\n","Epoch 00009: loss improved from 1.00075 to 1.00072, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BPCL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","787/787 [==============================] - 26s 33ms/step - loss: 0.8587\n","\n","Epoch 00010: loss did not improve from 1.00072\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7068324483488772\n","Mean Squared Error: 1.0000056911129311\n","Root Mean Squared Error: 1.000002845552417\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.619359405649918\n","Mean Squared Error: 13.732819130515141\n","Root Mean Squared Error: 3.70578185144716\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","775/775 [==============================] - 32s 37ms/step - loss: 0.9657\n","\n","Epoch 00001: loss improved from inf to 1.00396, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","775/775 [==============================] - 28s 36ms/step - loss: 1.0594\n","\n","Epoch 00002: loss improved from 1.00396 to 1.00112, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","775/775 [==============================] - 28s 36ms/step - loss: 1.0770\n","\n","Epoch 00003: loss improved from 1.00112 to 1.00099, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","775/775 [==============================] - 28s 36ms/step - loss: 1.2205\n","\n","Epoch 00004: loss did not improve from 1.00099\n","Epoch 5/10\n","775/775 [==============================] - 29s 37ms/step - loss: 1.0538\n","\n","Epoch 00005: loss improved from 1.00099 to 1.00087, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","775/775 [==============================] - 28s 36ms/step - loss: 1.0782\n","\n","Epoch 00006: loss did not improve from 1.00087\n","Epoch 7/10\n","775/775 [==============================] - 27s 35ms/step - loss: 1.0833\n","\n","Epoch 00007: loss improved from 1.00087 to 1.00077, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 8/10\n","775/775 [==============================] - 27s 35ms/step - loss: 0.9135\n","\n","Epoch 00008: loss improved from 1.00077 to 1.00056, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","775/775 [==============================] - 28s 36ms/step - loss: 1.0103\n","\n","Epoch 00009: loss did not improve from 1.00056\n","Epoch 10/10\n","775/775 [==============================] - 27s 35ms/step - loss: 1.0089\n","\n","Epoch 00010: loss improved from 1.00056 to 1.00041, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BHARTIARTL/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7425291719270138\n","Mean Squared Error: 0.9974561019153849\n","Root Mean Squared Error: 0.9987272409999564\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 2.223305045060162\n","Mean Squared Error: 8.942621663773883\n","Root Mean Squared Error: 2.9904216531743284\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","786/786 [==============================] - 31s 35ms/step - loss: 0.8215\n","\n","Epoch 00001: loss improved from inf to 1.00297, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BRITANNIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","786/786 [==============================] - 28s 36ms/step - loss: 1.0702\n","\n","Epoch 00002: loss did not improve from 1.00297\n","Epoch 3/10\n","786/786 [==============================] - 28s 35ms/step - loss: 1.0232\n","\n","Epoch 00003: loss improved from 1.00297 to 1.00095, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BRITANNIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","786/786 [==============================] - 28s 36ms/step - loss: 1.0216\n","\n","Epoch 00004: loss did not improve from 1.00095\n","Epoch 5/10\n","786/786 [==============================] - 27s 34ms/step - loss: 0.8694\n","\n","Epoch 00005: loss did not improve from 1.00095\n","Epoch 6/10\n","786/786 [==============================] - 28s 36ms/step - loss: 1.1010\n","\n","Epoch 00006: loss improved from 1.00095 to 1.00074, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BRITANNIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","786/786 [==============================] - 28s 36ms/step - loss: 1.1329\n","\n","Epoch 00007: loss did not improve from 1.00074\n","Epoch 8/10\n","786/786 [==============================] - 30s 38ms/step - loss: 0.9582\n","\n","Epoch 00008: loss did not improve from 1.00074\n","Epoch 9/10\n","786/786 [==============================] - 30s 38ms/step - loss: 0.8968\n","\n","Epoch 00009: loss improved from 1.00074 to 1.00006, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BRITANNIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","786/786 [==============================] - 31s 39ms/step - loss: 1.1110\n","\n","Epoch 00010: loss improved from 1.00006 to 0.99933, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/BRITANNIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.6639904178204826\n","Mean Squared Error: 0.9968280839497876\n","Root Mean Squared Error: 0.9984127823449516\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 1.425933424711927\n","Mean Squared Error: 4.597218432602429\n","Root Mean Squared Error: 2.1441125046513836\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","796/796 [==============================] - 34s 38ms/step - loss: 0.8643\n","\n","Epoch 00001: loss improved from inf to 1.00189, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","796/796 [==============================] - 30s 38ms/step - loss: 1.4344\n","\n","Epoch 00002: loss improved from 1.00189 to 1.00167, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","796/796 [==============================] - 29s 36ms/step - loss: 0.9372\n","\n","Epoch 00003: loss improved from 1.00167 to 1.00113, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","796/796 [==============================] - 30s 38ms/step - loss: 0.9873\n","\n","Epoch 00004: loss improved from 1.00113 to 1.00030, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","796/796 [==============================] - 30s 38ms/step - loss: 1.1304\n","\n","Epoch 00005: loss improved from 1.00030 to 0.99939, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","796/796 [==============================] - 31s 39ms/step - loss: 1.1489\n","\n","Epoch 00006: loss improved from 0.99939 to 0.99881, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","796/796 [==============================] - 30s 37ms/step - loss: 261.6980\n","\n","Epoch 00007: loss did not improve from 0.99881\n","Epoch 8/10\n","796/796 [==============================] - 28s 36ms/step - loss: 0.9776\n","\n","Epoch 00008: loss improved from 0.99881 to 0.98309, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","796/796 [==============================] - 28s 35ms/step - loss: 0.8242\n","\n","Epoch 00009: loss improved from 0.98309 to 0.97833, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/CIPLA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 10/10\n","796/796 [==============================] - 29s 36ms/step - loss: 120103.3812\n","\n","Epoch 00010: loss did not improve from 0.97833\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.7436420994197076\n","Mean Squared Error: 0.9983762079846944\n","Root Mean Squared Error: 0.9991877741369208\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 1.893545588317192\n","Mean Squared Error: 6.473181994763571\n","Root Mean Squared Error: 2.544244877122399\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","790/790 [==============================] - 32s 36ms/step - loss: 0.9602\n","\n","Epoch 00001: loss improved from inf to 1.00152, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","790/790 [==============================] - 27s 34ms/step - loss: 1.0298\n","\n","Epoch 00002: loss improved from 1.00152 to 1.00125, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","790/790 [==============================] - 29s 36ms/step - loss: 1.0042\n","\n","Epoch 00003: loss improved from 1.00125 to 1.00093, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","790/790 [==============================] - 28s 35ms/step - loss: 0.8855\n","\n","Epoch 00004: loss improved from 1.00093 to 1.00089, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","790/790 [==============================] - 28s 36ms/step - loss: 1.0636\n","\n","Epoch 00005: loss improved from 1.00089 to 1.00067, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","790/790 [==============================] - 28s 35ms/step - loss: 0.8819\n","\n","Epoch 00006: loss did not improve from 1.00067\n","Epoch 7/10\n","790/790 [==============================] - 29s 37ms/step - loss: 0.9179\n","\n","Epoch 00007: loss did not improve from 1.00067\n","Epoch 8/10\n","790/790 [==============================] - 29s 37ms/step - loss: 0.9049\n","\n","Epoch 00008: loss improved from 1.00067 to 1.00067, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/COALINDIA/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 9/10\n","790/790 [==============================] - 28s 36ms/step - loss: 1.0779\n","\n","Epoch 00009: loss did not improve from 1.00067\n","Epoch 10/10\n","790/790 [==============================] - 28s 35ms/step - loss: 1.1046\n","\n","Epoch 00010: loss did not improve from 1.00067\n","\n","ERROR VALUES FOR NORMALIZED RETURN PERCENTS\n","Mean Absolute Error: 0.8075873002384129\n","Mean Squared Error: 1.0000172224801371\n","Root Mean Squared Error: 1.0000086112029922\n","\n","ERROR VALUES FOR ACTUAL RETURN PERCENTS\n","Mean Absolute Error: 1.985522097588929\n","Mean Squared Error: 6.044744762699975\n","Root Mean Squared Error: 2.458606264268432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[i] = 100 * (self._dip[i] / self._trs[i])\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n","  din[i] = 100 * (self._din[i] / self._trs[i])\n"]},{"name":"stdout","output_type":"stream","text":["\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/10\n","797/797 [==============================] - 32s 36ms/step - loss: 0.9086\n","\n","Epoch 00001: loss improved from inf to 1.00760, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 2/10\n","797/797 [==============================] - 28s 35ms/step - loss: 0.9542\n","\n","Epoch 00002: loss improved from 1.00760 to 1.00279, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 3/10\n","797/797 [==============================] - 27s 34ms/step - loss: 0.8846\n","\n","Epoch 00003: loss improved from 1.00279 to 1.00252, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 4/10\n","797/797 [==============================] - 29s 36ms/step - loss: 0.9469\n","\n","Epoch 00004: loss improved from 1.00252 to 1.00111, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 5/10\n","797/797 [==============================] - 29s 36ms/step - loss: 1.0011\n","\n","Epoch 00005: loss improved from 1.00111 to 0.99988, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 6/10\n","797/797 [==============================] - 28s 36ms/step - loss: 1.1168\n","\n","Epoch 00006: loss improved from 0.99988 to 0.99510, saving model to ./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/DIVISLAB/LSTM_period:2_splitfactor:0.8_epochs:10.h5\n","Epoch 7/10\n","797/797 [==============================] - 28s 35ms/step - loss: nan\n","\n","Epoch 00007: loss did not improve from 0.99510\n","Epoch 8/10\n","797/797 [==============================] - 29s 36ms/step - loss: nan\n","\n","Epoch 00008: loss did not improve from 0.99510\n","Epoch 9/10\n","797/797 [==============================] - 29s 36ms/step - loss: nan\n","\n","Epoch 00009: loss did not improve from 0.99510\n","Epoch 10/10\n","797/797 [==============================] - 29s 36ms/step - loss: nan\n","\n","Epoch 00010: loss did not improve from 0.99510\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-4-65a6c15a6c5e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# For normalized return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 87\u001b[0;31m     \u001b[0mnormalized_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_standard_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mnormalized_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_standard_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mnormalized_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_standard_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m    177\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--\u003e 178\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 86\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--\u003e 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---\u003e 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."]}],"source":["companies_data = os.listdir('./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Storage/')\n","\n","# For each company, generate models according to differrent configurations\n","for company_csv in companies_data:\n","  company_df = pd.read_csv(f'./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Storage/{company_csv}')\n","  \n","  # Calcuate returns according to prediction periods in config\n","  for prediction_period in prediction_periods:\n","    company_df[f'returns_period_{prediction_period}'] = list(company_df['close'][prediction_period:]) + [None for i in range(prediction_period)]\n","    company_df[f'returns_period_{prediction_period}'] = ((company_df[f'returns_period_{prediction_period}'] - company_df['close']) / company_df['close'])*100\n","  company_df.dropna(inplace=True)\n","\n","  # Create 5 models per company\n","  for i in range(5):\n","\n","    prediction_period = prediction_periods[i]\n","\n","    # Split into test and train sets\n","    msk = np.random.rand(len(company_df)) \u003c train_test_split_factors[i]\n","    train_df = company_df.copy()[msk]\n","    test_df = company_df.copy()[~msk]\n","\n","    # Train set\n","    X_train = train_df.copy()\n","    X_train.drop(list(X_train.filter(regex='returns'))+['time_stamp'], axis=1, inplace=True)\n","    y_train = train_df.copy()[f'returns_period_{prediction_period}']\n","\n","    # Test set\n","    X_test = test_df.copy()\n","    X_test.drop(list(X_test.filter(regex='returns'))+['time_stamp'], axis=1, inplace=True)\n","    y_test = test_df.copy()[f'returns_period_{prediction_period}']\n","\n","    # Add indicators\n","    X_train = ta.add_all_ta_features(X_train, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n","    X_test = ta.add_all_ta_features(X_test, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n","\n","    # Scale and Reshape datasets\n","    \n","    # Set scaler\n","    scaler = StandardScaler()\n","\n","    # Scale and Reshape X_train\n","    X_train_standard_scaled = X_train.values\n","    X_train_standard_scaled = scaler.fit_transform(X_train_standard_scaled)\n","    X_train_standard_scaled = X_train_standard_scaled.reshape(X_train_standard_scaled.shape[0], X_train_standard_scaled.shape[1], 1)\n","\n","    # Scale and Reshape X_test\n","    X_test_standard_scaled = X_test.values\n","    X_test_standard_scaled = scaler.fit_transform(X_test_standard_scaled)\n","    X_test_standard_scaled = X_test_standard_scaled.reshape(X_test_standard_scaled.shape[0], X_test_standard_scaled.shape[1], 1)\n","\n","    # Scale and Reshape y_train\n","    y_train_standard_scaled = y_train.values\n","    y_train_standard_scaled = y_train_standard_scaled.reshape(y_train_standard_scaled.shape[0], 1)\n","    y_train_standard_scaled = scaler.fit_transform(y_train_standard_scaled)\n","\n","    # Scale and Reshape y_test\n","    y_test_standard_scaled = y_test.values\n","    y_test_standard_scaled = y_test_standard_scaled.reshape(y_test_standard_scaled.shape[0], 1)\n","    y_test_standard_scaled = scaler.fit_transform(y_test_standard_scaled)\n","\n","    # Define model\n","    model = Sequential()\n","    model.add(LSTM(hidden_layer_configs[i][0], activation=activation, return_sequences=True, input_shape=(89, 1)))\n","    for layer in range(1, len(hidden_layer_configs[i]) - 1):\n","      model.add(LSTM(hidden_layer_configs[i][layer], activation=activation, return_sequences=True))\n","    model.add(LSTM(hidden_layer_configs[i][-1], activation=activation))\n","    model.add(Dense(1))\n","    model.compile(optimizer=optimizer, loss=loss)\n","\n","    # Show a summary of the model\n","    print()\n","    # model.summary()\n","\n","    # String to save model\n","    save_string = f\"./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/{company_csv[:-7]}/LSTM_period:{prediction_period}_splitfactor:{train_test_split_factors[i]}_epochs:{epochs[i]}.h5\"\n","\n","    # Train model\n","    checkpoint = ModelCheckpoint(save_string, monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n","    model.fit(X_train_standard_scaled, y_train_standard_scaled, epochs=epochs[i], batch_size=1, callbacks=[checkpoint])\n","\n","    # Test model\n","    predictions = model.predict(X_test_standard_scaled)\n","    prediction_percents = scaler.inverse_transform(predictions)\n","\n","    # For normalized return\n","    normalized_mae = metrics.mean_absolute_error(y_test_standard_scaled, predictions)\n","    normalized_mse = metrics.mean_squared_error(y_test_standard_scaled, predictions)\n","    normalized_rmse = np.sqrt(metrics.mean_squared_error(y_test_standard_scaled, predictions))\n","\n","    print()\n","    print('ERROR VALUES FOR NORMALIZED RETURN PERCENTS')\n","    print('Mean Absolute Error:', normalized_mae)\n","    print('Mean Squared Error:', normalized_mse)\n","    print('Root Mean Squared Error:', normalized_rmse)\n","\n","    # For actual return percents\n","    actual_mae = metrics.mean_absolute_error(y_test, prediction_percents)\n","    actual_mse = metrics.mean_squared_error(y_test, prediction_percents)\n","    actual_rmse = np.sqrt(metrics.mean_squared_error(y_test, prediction_percents))\n","\n","    print()\n","    print('ERROR VALUES FOR ACTUAL RETURN PERCENTS')\n","    print('Mean Absolute Error:', actual_mae)\n","    print('Mean Squared Error:', actual_mse)\n","    print('Root Mean Squared Error:', actual_rmse)\n","\n","    # Rename saved model with more info\n","    new_save_string = f\"./drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Models/{company_csv[:-7]}/LSTM_period:{prediction_period}_splitfactor:{train_test_split_factors[i]}_epochs:{epochs[i]}_nmae:{normalized_mae}_nmse:{normalized_mse}__nrmse:{normalized_rmse}__mae:{actual_mae}__mse:{actual_mse}__rmse:{actual_rmse}_.h5\"\n","    os.rename(save_string, new_save_string)\n","\n","    # Consider building just one model for now\n","    break\n","\n","  # Consider just one company for now  \n","  # break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_UniFYUpPny5"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOOKBssn6qYBVNoIh4AkIEb","collapsed_sections":[],"mount_file_id":"1Os_T2n7AeVax3pEXznM4c2B0SgQBLZRx","name":"generate_models.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}